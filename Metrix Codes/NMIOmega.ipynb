{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NMIOmega.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bcl0LiqHngOC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81b80ec8-045e-44e1-cf5b-d73564f3846d"
      },
      "source": [
        "!pip install cdlib"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cdlib\n",
            "  Using cached cdlib-0.2.4-py3-none-any.whl (208 kB)\n",
            "Collecting eva-lcd\n",
            "  Using cached eva_lcd-0.1.1-py3-none-any.whl (9.2 kB)\n",
            "Collecting angel-cd\n",
            "  Using cached angel_cd-1.0.3-py3-none-any.whl (10 kB)\n",
            "Collecting bimlpa\n",
            "  Using cached bimlpa-0.1.2-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from cdlib) (0.22.2.post1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from cdlib) (0.16.0)\n",
            "Collecting markov-clustering\n",
            "  Using cached markov_clustering-0.0.6.dev0-py3-none-any.whl (6.3 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from cdlib) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from cdlib) (1.19.5)\n",
            "Collecting leidenalg\n",
            "  Using cached leidenalg-0.8.7-cp37-cp37m-manylinux2010_x86_64.whl (1.4 MB)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from cdlib) (0.29.24)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.7/dist-packages (from cdlib) (0.15)\n",
            "Collecting dynetx\n",
            "  Using cached dynetx-0.3.0-py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.7/dist-packages (from cdlib) (2.6.2)\n",
            "Collecting wurlitzer\n",
            "  Using cached wurlitzer-3.0.2-py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from cdlib) (1.1.5)\n",
            "Collecting nf1\n",
            "  Using cached nf1-0.0.4-py3-none-any.whl (18 kB)\n",
            "Collecting infomap\n",
            "  Using cached infomap-1.6.0.tar.gz (276 kB)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from cdlib) (0.11.1)\n",
            "Collecting python-Levenshtein\n",
            "  Using cached python-Levenshtein-0.12.2.tar.gz (50 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from cdlib) (4.62.0)\n",
            "Collecting pulp\n",
            "  Using cached PuLP-2.5.0-py3-none-any.whl (41.2 MB)\n",
            "Collecting thresholdclustering\n",
            "  Using cached thresholdclustering-1.1-py3-none-any.whl (5.3 kB)\n",
            "Collecting demon\n",
            "  Using cached demon-2.0.6-py3-none-any.whl (7.3 kB)\n",
            "Collecting python-igraph\n",
            "  Using cached python_igraph-0.9.6-cp37-cp37m-manylinux2010_x86_64.whl (3.2 MB)\n",
            "Collecting karateclub\n",
            "  Using cached karateclub-1.2.1.tar.gz (59 kB)\n",
            "Collecting chinese-whispers\n",
            "  Using cached chinese_whispers-0.7.5-py3-none-any.whl (7.6 kB)\n",
            "Collecting pyclustering\n",
            "  Using cached pyclustering-0.10.1.2.tar.gz (2.6 MB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from cdlib) (1.4.1)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.7/dist-packages (from cdlib) (1.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from dynetx->cdlib) (4.4.2)\n",
            "Collecting pygsp\n",
            "  Using cached PyGSP-0.5.1-py2.py3-none-any.whl (1.8 MB)\n",
            "Collecting gensim>=4.0.0\n",
            "  Using cached gensim-4.1.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from karateclub->cdlib) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=4.0.0->karateclub->cdlib) (5.1.0)\n",
            "Collecting texttable>=1.6.2\n",
            "  Using cached texttable-1.6.4-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cdlib) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cdlib) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cdlib) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cdlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->cdlib) (2018.9)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch->cdlib) (1.4.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pooch->cdlib) (21.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch->cdlib) (2.23.0)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from pyclustering->cdlib) (7.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein->cdlib) (57.4.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch->cdlib) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch->cdlib) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch->cdlib) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch->cdlib) (2021.5.30)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->cdlib) (1.0.1)\n",
            "Building wheels for collected packages: infomap, karateclub, pyclustering, python-Levenshtein\n",
            "  Building wheel for infomap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for infomap: filename=infomap-1.6.0-cp37-cp37m-linux_x86_64.whl size=5622491 sha256=9901dc4f8426afe7fb65f93479ba9561553c863b7f709705d5c57844787f8379\n",
            "  Stored in directory: /root/.cache/pip/wheels/36/ae/2d/50a0933445cc36de4256233124cf464083d4bc0db290375c82\n",
            "  Building wheel for karateclub (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for karateclub: filename=karateclub-1.2.1-py3-none-any.whl size=94671 sha256=6351b94ee8f97bed0d0900e95e33a97b9b693293ec000f05301474b6ff32b471\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/d3/49/b058bfc660537177cefe9bd1f53de94e9762bd1c5ef668a523\n",
            "  Building wheel for pyclustering (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyclustering: filename=pyclustering-0.10.1.2-py3-none-any.whl size=2395121 sha256=2960e4c3c2533f655144fc04177e97e1c4b8ef8c160e56262a839472b5cc04a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/87/6b/1e0568b5ba9dc6518a25338bae90bd8392f35206bb90bb10f1\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149867 sha256=b2ae2f165ad443fb2a040dc75badcec262be69801731c5ab8005efc211540323\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n",
            "Successfully built infomap karateclub pyclustering python-Levenshtein\n",
            "Installing collected packages: texttable, python-igraph, pygsp, gensim, wurlitzer, thresholdclustering, python-Levenshtein, pyclustering, pulp, nf1, markov-clustering, leidenalg, karateclub, infomap, eva-lcd, dynetx, demon, chinese-whispers, bimlpa, angel-cd, cdlib\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed angel-cd-1.0.3 bimlpa-0.1.2 cdlib-0.2.4 chinese-whispers-0.7.5 demon-2.0.6 dynetx-0.3.0 eva-lcd-0.1.1 gensim-4.1.1 infomap-1.6.0 karateclub-1.2.1 leidenalg-0.8.7 markov-clustering-0.0.6.dev0 nf1-0.0.4 pulp-2.5.0 pyclustering-0.10.1.2 pygsp-0.5.1 python-Levenshtein-0.12.2 python-igraph-0.9.6 texttable-1.6.4 thresholdclustering-1.1 wurlitzer-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFEFSlKHnm-5"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import networkx as nx\n",
        "import pandas as pd \n",
        "from cdlib import NodeClustering, evaluation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a8khK3MnnNN"
      },
      "source": [
        "def get_communities(path, first_delimiter, delimiter, seperate_comm_id):\n",
        "    comm_dict = dict()\n",
        "    with open(path, \"rt\") as f:\n",
        "        for row in f:\n",
        "            node, row = row.rstrip().split(first_delimiter, 1)\n",
        "            node = int(node)\n",
        "            record = list(map(int, row.split(delimiter)))\n",
        "            for comm_id in record:\n",
        "                if comm_id in comm_dict.keys():\n",
        "                    comm_dict[comm_id].append(node)\n",
        "                else:\n",
        "                    comm_dict[comm_id] = [node]\n",
        "    communities = []\n",
        "    for k, v in comm_dict.items():\n",
        "        if not seperate_comm_id:\n",
        "            v.append(k)\n",
        "        communities.append(v)\n",
        "    return communities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXbrDBNmnnfI"
      },
      "source": [
        "\n",
        "def main():\n",
        "    NMI_result = dict()\n",
        "    Omega_result = dict()\n",
        "    for N in [1000, 5000, 10000]:\n",
        "        NMI_result[N] = dict()\n",
        "        Omega_result[N] = dict()\n",
        "        for mu in [0.1, 0.3]:\n",
        "            NMI_result[N][mu] = {'NMI':[], 'NMI_max':[]}\n",
        "            Omega_result[N][mu] = {'omega':[]}\n",
        "            for om in range(2,9):\n",
        "                communities = get_communities(os.path.join('N-{}-mu{:1.1f}-om{}-result.txt'.format(N, mu, om)), \" \", \" \", False)\n",
        "                gt_communities = get_communities(os.path.join('N-{}-mu{:1.1f}-om{}-community.txt'.format(N, mu, om)), \"\\t\", \" \", True)\n",
        "                df = pd.read_csv('N-{}-mu{:1.1f}-om{}.csv'.format(N, mu, om))\n",
        "                G = nx.from_pandas_edgelist(df,source=\"From\",target=\"To\")\n",
        "                coms = NodeClustering(communities, G, \"\", overlap=True)\n",
        "                gt_coms = NodeClustering(gt_communities, G, \"\", overlap=True)\n",
        "                nmi = evaluation.overlapping_normalized_mutual_information_LFK(coms, gt_coms)[0]\n",
        "                nmi_max = evaluation.overlapping_normalized_mutual_information_MGH(coms, gt_coms)[0]\n",
        "                omega = evaluation.omega(coms, gt_coms)[0]\n",
        "                NMI_result[N][mu]['NMI'].append(nmi)\n",
        "                NMI_result[N][mu]['NMI_max'].append(nmi_max)\n",
        "                Omega_result[N][mu]['omega'].append(omega)\n",
        "\n",
        "                #print(\"\\nN: \", N,\"mu: \", mu,\"om: \", om,\"NMI_result: \", NMI_result, \"Omega_result: \", Omega_result)\n",
        "        \n",
        "        with open('LFR_nmi.json', 'w') as f:\n",
        "            json.dump(NMI_result, f)\n",
        "        with open('LFR_omega.json', 'w') as f:\n",
        "            json.dump(Omega_result, f)\n",
        "      \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRNwjyP2nnoH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "23764fa1-c6d6-4398-8671-2aa53b9eaec3"
      },
      "source": [
        "\"\"\"\n",
        "def main():\n",
        "    NMI_result = dict()\n",
        "    Omega_result = dict()\n",
        "    N=10000\n",
        "    mu=0.1\n",
        "    om=2\n",
        "    NMI_result[N] = dict()\n",
        "    Omega_result[N] = dict()\n",
        "        \n",
        "    NMI_result[N][mu] = {'NMI':[], 'NMI_max':[]}\n",
        "    Omega_result[N][mu] = {'omega':[]}\n",
        "                \n",
        "    communities = get_communities(os.path.join('N-{}-mu{:1.1f}-om{}-result.txt'.format(N, mu, om)), \" \", \" \", False)\n",
        "    gt_communities = get_communities(os.path.join('N-{}-mu{:1.1f}-om{}-community.txt'.format(N, mu, om)), \"\\t\", \" \", True)\n",
        "    df = pd.read_csv('N-{}-mu{:1.1f}-om{}.csv'.format(N, mu, om))\n",
        "    G = nx.from_pandas_edgelist(df,source=\"From\",target=\"To\")\n",
        "    coms = NodeClustering(communities, G, \"\", overlap=True)\n",
        "    gt_coms = NodeClustering(gt_communities, G, \"\", overlap=True)\n",
        "    #nmi = evaluation.overlapping_normalized_mutual_information_LFK(coms, gt_coms)[0]\n",
        "    #nmi_max = evaluation.overlapping_normalized_mutual_information_MGH(coms, gt_coms)[0]\n",
        "    omega = evaluation.omega(coms, gt_coms)[0]\n",
        "    #NMI_result[N][mu]['NMI'].append(nmi)\n",
        "    #NMI_result[N][mu]['NMI_max'].append(nmi_max)\n",
        "    #Omega_result[N][mu]['omega'].append(omega)\n",
        "\n",
        "    print(omega)\n",
        "    \n",
        "    #with open('LFR_nmi.json', 'w') as f:\n",
        "    #json.dump(NMI_result, f)\n",
        "    #with open('LFR_omega.json', 'w') as f:\n",
        "    #json.dump(Omega_result, f)\n",
        "    \n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ndef main():\\n    NMI_result = dict()\\n    Omega_result = dict()\\n    N=10000\\n    mu=0.1\\n    om=2\\n    NMI_result[N] = dict()\\n    Omega_result[N] = dict()\\n        \\n    NMI_result[N][mu] = {\\'NMI\\':[], \\'NMI_max\\':[]}\\n    Omega_result[N][mu] = {\\'omega\\':[]}\\n                \\n    communities = get_communities(os.path.join(\\'N-{}-mu{:1.1f}-om{}-result.txt\\'.format(N, mu, om)), \" \", \" \", False)\\n    gt_communities = get_communities(os.path.join(\\'N-{}-mu{:1.1f}-om{}-community.txt\\'.format(N, mu, om)), \"\\t\", \" \", True)\\n    df = pd.read_csv(\\'N-{}-mu{:1.1f}-om{}.csv\\'.format(N, mu, om))\\n    G = nx.from_pandas_edgelist(df,source=\"From\",target=\"To\")\\n    coms = NodeClustering(communities, G, \"\", overlap=True)\\n    gt_coms = NodeClustering(gt_communities, G, \"\", overlap=True)\\n    #nmi = evaluation.overlapping_normalized_mutual_information_LFK(coms, gt_coms)[0]\\n    #nmi_max = evaluation.overlapping_normalized_mutual_information_MGH(coms, gt_coms)[0]\\n    omega = evaluation.omega(coms, gt_coms)[0]\\n    #NMI_result[N][mu][\\'NMI\\'].append(nmi)\\n    #NMI_result[N][mu][\\'NMI_max\\'].append(nmi_max)\\n    #Omega_result[N][mu][\\'omega\\'].append(omega)\\n\\n    print(omega)\\n    \\n    #with open(\\'LFR_nmi.json\\', \\'w\\') as f:\\n    #json.dump(NMI_result, f)\\n    #with open(\\'LFR_omega.json\\', \\'w\\') as f:\\n    #json.dump(Omega_result, f)\\n    \\n'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pr9rt6YhnnxQ"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wJGANNJnn5O"
      },
      "source": [
        "\"\"\"\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}